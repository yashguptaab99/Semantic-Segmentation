{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Segmentation.ipynb",
      "provenance": [],
      "mount_file_id": "1rSrgjFK97jP8gCu4t0tV6myFVgg13Jd6",
      "authorship_tag": "ABX9TyOrPWUcvLcL3f/z5JK2+j0+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashguptaab99/Semantic-Segmentation/blob/master/Semantic_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I96d_nFfCmrN",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ1gBkjiSzkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "bc81a096-41ef-4eb5-bdb1-bbd7eb050779"
      },
      "source": [
        "!git clone \"https://github.com/yashguptaab99/Semantic-Segmentation.git\"\n",
        "!pip install \"/content/Semantic-Segmentation/data_generator.py\"\n",
        "!pip install \"/content/Semantic-Segmentation/models.py\"\n",
        "!pip install \"/content/Semantic-Segmentation/config.py\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Semantic-Segmentation' already exists and is not an empty directory.\n",
            "\u001b[31mERROR: Invalid requirement: '/content/Semantic-Segmentation/data_generator.py'\n",
            "Hint: It looks like a path. File '/content/Semantic-Segmentation/data_generator.py' does not exist.\u001b[0m\n",
            "\u001b[31mERROR: Invalid requirement: '/content/Semantic-Segmentation/models.py'\n",
            "Hint: It looks like a path. File '/content/Semantic-Segmentation/models.py' does not exist.\u001b[0m\n",
            "\u001b[31mERROR: Invalid requirement: '/content/Semantic-Segmentation/config.py'\n",
            "Hint: It looks like a path. File '/content/Semantic-Segmentation/config.py' does not exist.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5JPOhwnCpXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "f1cb4739-3bad-418c-fa98-0a1162497dae"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from config import model_name, n_classes, imshape, labels, hues, mode\n",
        "from models import unet, fcn_8\n",
        "from data_generator import DataGenerator\n",
        "from PIL import Image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import json\n",
        "##upload annotated, images, config, datageneration, models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b2c3026aa725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcn_8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlP8CVebFLPW",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ30CkEaEiam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_missing_json():\n",
        "\n",
        "    # creates a background json for the entire image if missing\n",
        "    # this assumes you will never annotate a background class\n",
        "\n",
        "    for im in os.listdir('drive/My Drive/Projects/Semantic-Shapes-master/images'):\n",
        "        fn = im.split('.')[0]+'.json'\n",
        "        path = os.path.join('drive/My Drive/Projects/Semantic-Shapes-master/annotated', fn)\n",
        "\n",
        "        if os.path.exists(path) is False:\n",
        "            json_dict = {}\n",
        "\n",
        "            # these points might be reversed if not using a square image (idk)\n",
        "            json_dict['shapes'] = [{\"label\": \"background\",\n",
        "                                    \"points\": [[0,0],\n",
        "                                               [0, imshape[0]-1],\n",
        "                                               [imshape[0]-1, imshape[1]-1],\n",
        "                                               [imshape[0]-1, 0]]\n",
        "                                    }]\n",
        "            with open(path, 'w') as handle:\n",
        "                json.dump(json_dict, handle, indent=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6V__DKhEHYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sorted_fns(dir):\n",
        "    return sorted(os.listdir(dir), key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "if len(os.listdir('drive/My Drive/Projects/Semantic-Shapes-master/images')) != len(os.listdir('drive/My Drive/Projects/Semantic-Shapes-master/annotated')):\n",
        "    generate_missing_json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbbG3w00Ez8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_paths = [os.path.join('drive/My Drive/Projects/Semantic-Shapes-master/images', x) for x in sorted_fns('/content/drive/My Drive/Projects/Semantic-Shapes-master/images')]\n",
        "annot_paths = [os.path.join('drive/My Drive/Projects/Semantic-Shapes-master/annotated', x) for x in sorted_fns('/content/drive/My Drive/Projects/Semantic-Shapes-master/annotated')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4Yw6eo_HSj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tg = DataGenerator(image_paths=image_paths, annot_paths=annot_paths,\n",
        "                   batch_size=5, augment=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LArrfoArHfC6",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD9vlLtVFEDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = fcn_8(pretrained=False, base=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-DoJ9S_FXyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(generator=tg,\n",
        "                    steps_per_epoch=len(tg),\n",
        "                    epochs=500, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umM7YfZ0MHJj",
        "colab_type": "text"
      },
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1zDBUXzML7V",
        "colab_type": "text"
      },
      "source": [
        "## Mask Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqeMyezhzbsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_masks(pred):\n",
        "    blank = np.zeros(shape=imshape, dtype=np.uint8)\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "\n",
        "        hue = np.full(shape=(imshape[0], imshape[1]), fill_value=hues[label], dtype=np.uint8)\n",
        "        sat = np.full(shape=(imshape[0], imshape[1]), fill_value=255, dtype=np.uint8)\n",
        "        val = pred[:,:,i].astype(np.uint8)\n",
        "\n",
        "        im_hsv = cv2.merge([hue, sat, val])\n",
        "        im_rgb = cv2.cvtColor(im_hsv, cv2.COLOR_HSV2RGB)\n",
        "        blank = cv2.add(blank, im_rgb)\n",
        "\n",
        "    return blank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL4mY2hEMRhR",
        "colab_type": "text"
      },
      "source": [
        "### Conditional Random Fields (CFR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXfRfrpX7qz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pydensecrf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evwS2RTb_1GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax\n",
        "def crf(im_softmax, im_rgb):\n",
        "    n_classes = im_softmax.shape[2]\n",
        "    feat_first = im_softmax.transpose((2, 0, 1)).reshape(n_classes, -1)\n",
        "    unary = unary_from_softmax(feat_first)\n",
        "    unary = np.ascontiguousarray(unary)\n",
        "    im_rgb = np.ascontiguousarray(im_rgb)\n",
        "\n",
        "    d = dcrf.DenseCRF2D(im_rgb.shape[1], im_rgb.shape[0], n_classes)\n",
        "\n",
        "    d.setUnaryEnergy(unary)\n",
        "    d.addPairwiseGaussian(sxy=(5, 5), compat=3, kernel=dcrf.DIAG_KERNEL,\n",
        "                              normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
        "\n",
        "    # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
        "    d.addPairwiseBilateral(sxy=(5, 5), srgb=(13, 13, 13), rgbim=im_rgb,\n",
        "                           compat=10,\n",
        "                           kernel=dcrf.DIAG_KERNEL,\n",
        "                           normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
        "    Q = d.inference(5)\n",
        "    res = np.argmax(Q, axis=0).reshape((im_rgb.shape[0], im_rgb.shape[1]))\n",
        "    if mode is 'binary':\n",
        "        return res * 255.0\n",
        "    if mode is 'multi':\n",
        "        res_hot = to_categorical(res) * 255.0\n",
        "        res_crf = add_masks(res_hot)\n",
        "        return res_crf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "137L75pPMmYE",
        "colab_type": "text"
      },
      "source": [
        "## Output Result\n",
        "We can see CFR is giving better result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq9Lhbks80sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "path = '/content/Semantic-Segmentation/test1.jpg'\n",
        "im = cv2.imread(path)\n",
        "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "im = cv2.resize(im, (256, 256), interpolation = cv2.INTER_AREA)\n",
        "tm = np.expand_dims(im, axis=0)\n",
        "im_pred = model.predict(tm)\n",
        "im_mask1 = add_masks(im_pred.squeeze()*255.0)\n",
        "im_mask2 = crf(im_pred.squeeze(), im)\n",
        "cv2_imshow(im_mask1)\n",
        "cv2_imshow(im_mask2)\n",
        "cv2_imshow(im)\n",
        "cv2.imwrite(\"/content/output1.jpg\", im_mask2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMoUB4M5Ho-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "path = '/content/Semantic-Segmentation/test2.jpg'\n",
        "im = cv2.imread(path)\n",
        "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "im = cv2.resize(im, (256, 256), interpolation = cv2.INTER_AREA)\n",
        "tm = np.expand_dims(im, axis=0)\n",
        "im_pred = model.predict(tm)\n",
        "im_mask1 = add_masks(im_pred.squeeze()*255.0)\n",
        "im_mask2 = crf(im_pred.squeeze(), im)\n",
        "cv2_imshow(im_mask1)\n",
        "cv2_imshow(im_mask2)\n",
        "cv2_imshow(im)\n",
        "cv2.imwrite(\"/content/output2.jpg\", im_mask2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH6KHVKTM1sC",
        "colab_type": "text"
      },
      "source": [
        "# Assigning White Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-HkEw-hM8kg",
        "colab_type": "text"
      },
      "source": [
        "## Taking input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtWvHLipHxLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bg = cv2.imread(\"/content/Semantic-Segmentation/background.jpg\")\n",
        "bg = cv2.resize(bg, (256, 256), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "fg = cv2.imread(\"/content/Semantic-Segmentation/test2.jpg\")\n",
        "fg = cv2.resize(fg, (256, 256), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "mask = cv2.imread(\"/content/Semantic-Segmentation/output2.jpg\",0)\n",
        "mask = cv2.resize(mask, (256, 256), interpolation = cv2.INTER_AREA)\n",
        "ret, mask = cv2.threshold(mask, 15, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "mask2 = mask.copy()\n",
        "fg2 = fg.copy()\n",
        "bg2 = bg.copy()\n",
        "\n",
        "print('Mask : ',mask2.shape)\n",
        "print('FG : ',fg2.shape)\n",
        "print('BG : ',bg.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TFhAUsaNCBK",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axE0KQpA9Hr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RESIZE IMAGE BY WIDTH OR HEIGHT MAINTAINING ASPECT RATIO\n",
        "def maintain_aspect_ratio_resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
        "    # Grab the image size and initialize dimensions\n",
        "    dim = None\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    # Return original image if no need to resize\n",
        "    if width is None and height is None:\n",
        "        return image\n",
        "\n",
        "    # We are resizing height if width is none\n",
        "    if width is None:\n",
        "        # Calculate the ratio of the height and construct the dimensions\n",
        "        r = height / float(h)\n",
        "        dim = (int(w * r), height)\n",
        "    # We are resizing width if height is none\n",
        "    else:\n",
        "        # Calculate the ratio of the width and construct the dimensions\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "\n",
        "    # Return the resized image\n",
        "    return cv2.resize(image, dim, interpolation=inter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUq6wxAM51ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#openCV places height before width in shape[] array\n",
        "\n",
        "bgWidth = bg2.shape[1]\n",
        "bgHeight = bg2.shape[0]\n",
        "\n",
        "fgWidth = fg2.shape[1]\n",
        "fgHeight = fg2.shape[0]\n",
        "\n",
        "fg2 = maintain_aspect_ratio_resize(fg2, width=bgWidth)\n",
        "mask2 = maintain_aspect_ratio_resize(mask2, width=bgWidth)\n",
        "\n",
        "fgWidth = fg2.shape[1]\n",
        "fgHeight = fg2.shape[0]\n",
        "\n",
        "if fgHeight > bgHeight:\n",
        "  fg2 = maintain_aspect_ratio_resize(fg2, height=bgHeight)\n",
        "  mask2 = maintain_aspect_ratio_resize(mask2, height=bgHeight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6vYYj_L6ZAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Mask : ',mask2.shape)\n",
        "print('FG : ',fg2.shape)\n",
        "print('BG : ',bg.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bo2OUBRNKEX",
        "colab_type": "text"
      },
      "source": [
        "## Implement "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOvmgoro9LgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = cv2.GaussianBlur(mask2, (21,21),0)\n",
        "bg2[np.where(alpha > 150)] = fg2[np.where(alpha > 150)]\n",
        "output = bg2.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gllm2LvRNSaj",
        "colab_type": "text"
      },
      "source": [
        "## Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76JqOx1q9jVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(fg)\n",
        "cv2_imshow(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9oFGxMW9x3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2.imwrite(\"/content/Whiteoutput1.jpg\", output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1N-NbpZSOAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}